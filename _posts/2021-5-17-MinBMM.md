---
layout: post
title: Implementation Details of MinBMM
published: false
---

The output tensor no longer needs to be `[b, m, n]`, it should be `[b, m]` or `[b, n]` depending on which dimention the reduction is performed on. And for min / max reduction, it makes sense to also do argmin / argmax at the same time.  

Let's start. First allocate output tensors with pytorch:
```python
if dim == 1:
  values = torch.empty(b, n, device="cuda:0", dtype=torch.float32)
  indices = torch.empty(b, n, device="cuda:0", dtype=torch.int64)
elif dim == 2:
  values = torch.empty(b, m, device="cuda:0", dtype=torch.float32)
  indices = torch.empty(b, m, device="cuda:0", dtype=torch.int64)
else:
  raise NotImplementedError
```  

Because we will do `atomicMin` on `values`, the initial content of `values` should be as large as possible.
Fill `values` with ∞ for min (or -∞ for max):  
```python
values.fill_(float("-inf"))
```  

Then pass the pointer of the new output tensors and `dim` value to the cuda kernel:
```python
self._fn_nn(
  grid=blocks_per_grid,
  block=threads_per_block,
  args=[
    A.data_ptr(),
    B.data_ptr(),
    values.data_ptr(),  ###
    indices.data_ptr(), ###
    m, n, k,
    dim                 ###
  ],
  stream=self.stream
)
```

Now we are going to edit the BMM kernel. First change the kernel name and parameters:
```cpp
typedef long long ll_t;
extern "C"
__global__ void min_bmm_nn(
  const float* __restrict__ A,
  const float* __restrict__ B,
  float* values,
  ll_t* indices,
  int M, int N, int K, int DIM
)
```  

The only thing that needs to be changed is the last part of the kernel. we will replace `write_c` function with min/argmin reduction.
```c
// write_c(cCache, C, gStartx, gStarty, vx, vy, bid, M, N);
if (DIM == 1) {
  min_dim_1(
    cCache, aSM, bSM, values, indices,
    gStartx, gStarty, tid, bid, M, N);
} else if (DIM == 2) {
  min_dim_2(
    cCache, aSM, bSM, values, indices,
    gStartx, gStarty, tid, bid, M, N);
}
```  
We will write 2 versions of `min` for dim = 1 and dim = 2. let's start with `min_dim_1`:
```

```
